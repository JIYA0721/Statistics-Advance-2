{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#THEORY QUESTIONS"
      ],
      "metadata": {
        "id": "g8drtYY6k2yR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics?\n",
        "   - Hypothesis testing is a statistical method used to make decisions or inferences about a population based on a sample. It involves testing an assumption (hypothesis) about a population parameter.\n",
        "\n",
        "\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "   - Null hypothesis (H₀): Assumes no effect or no difference in the population.\n",
        "\n",
        "Alternative hypothesis (H₁ or Ha): Suggests there is an effect or a difference.\n",
        "\n",
        "They are mutually exclusive. You either reject H₀ or fail to reject it in favor of H₁.\n",
        "\n",
        "\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "   - The significance level (α) is the probability of rejecting the null hypothesis when it is actually true. Common values are 0.05 or 0.01. It sets the threshold for how strong the evidence must be to reject H₀.\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "   - The P-value is the probability of obtaining a test statistic as extreme as, or more extreme than, the observed one, assuming H₀ is true.\n",
        "\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "   - If P ≤ α, reject the null hypothesis (evidence supports H₁).\n",
        "\n",
        "If P > α, fail to reject the null hypothesis (insufficient evidence to support H₁).\n",
        "\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "   - Type I error (α): Rejecting H₀ when it is true.\n",
        "\n",
        "Type II error (β): Failing to reject H₀ when it is false.\n",
        "\n",
        "\n",
        "\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "   - One-tailed test: Tests for effect in one direction (e.g., μ > μ₀).\n",
        "\n",
        "Two-tailed test: Tests for effect in both directions (e.g., μ ≠ μ₀).\n",
        "\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "   - A Z-test is used when the population variance is known and the sample size is large (n > 30). It assesses whether sample means differ significantly from population means.\n",
        "\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "   - It measures how many standard deviations the sample mean is from the population mean (μ).\n",
        "\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "   - The T-distribution is used when the population standard deviation is unknown and the sample size is small (n < 30). It has heavier tails than the normal distribution.\n",
        "\n",
        "\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "   - Z-test: Known population variance, large sample.\n",
        "\n",
        "T-test: Unknown population variance, small sample.\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "   - A T-test assesses whether the means of two groups (or a sample and a population) are significantly different, using the sample standard deviation.\n",
        "\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "   - Both tests compare sample statistics to population parameters. The T-test is a generalization of the Z-test used when the population variance is unknown.\n",
        "\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "   - A confidence interval (CI) provides a range of values within which the true population parameter likely lies, with a certain confidence level (e.g., 95%).\n",
        "\n",
        "15. What is the margin of error, and how does it affect the confidence interval?\n",
        "   - The margin of error is the range added/subtracted from the point estimate to create the CI. A larger margin results in a wider interval, indicating more uncertainty.\n",
        "\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "   - Bayes’ Theorem calculates the probability of a hypothesis given new evidence. It is fundamental in Bayesian statistics and used in areas like diagnostic testing and machine learning.\n",
        "\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "   - The Chi-square (χ²) distribution is used in tests of categorical data (e.g., goodness-of-fit, independence). It’s right-skewed and based on squared deviations.\n",
        "\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "   - It tests whether an observed frequency distribution differs from an expected distribution. Used to assess if a sample matches a population.\n",
        "\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "   - The F-distribution is used to compare two variances or in ANOVA to test if means across multiple groups are equal. It's right-skewed and based on ratio of variances.\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "   - ANOVA (Analysis of Variance) tests for significant differences between group means. Assumptions:\n",
        "\n",
        "Independence of observations\n",
        "\n",
        "Normality\n",
        "\n",
        "Equal variances (homoscedasticity)\n",
        "\n",
        "\n",
        "\n",
        "21. What are the different types of ANOVA tests?\n",
        "   - One-way ANOVA: One independent variable\n",
        "\n",
        "Two-way ANOVA: Two independent variables\n",
        "\n",
        "Repeated measures ANOVA: Same subjects tested multiple times\n",
        "\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "   - The F-test compares variances to determine if they are significantly different. It is the basis of the ANOVA test and is used to test overall model significance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nDn-l1lDk9lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL QUESTIONS"
      ],
      "metadata": {
        "id": "pLwH_7D0rBPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data\n",
        "sample = [52, 55, 53, 54, 56, 58, 52, 53, 57, 54]  # example sample data\n",
        "sample_mean = np.mean(sample)\n",
        "sample_size = len(sample)\n",
        "\n",
        "# Known population parameters\n",
        "population_mean = 50\n",
        "population_std = 3  # Known population standard deviation\n",
        "\n",
        "# Z-test calculation\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "# Output the results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n"
      ],
      "metadata": {
        "id": "kZL3WaK4nO10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39gCrZvtkvtu"
      },
      "outputs": [],
      "source": [
        "# Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Simulate random data for the sample (e.g., heights in cm)\n",
        "np.random.seed(42)  # for reproducibility\n",
        "sample_size = 30\n",
        "population_mean = 170\n",
        "population_std = 10  # known population standard deviation\n",
        "\n",
        "# Generate sample data assuming it's drawn from a population with mean = 172\n",
        "sample_data = np.random.normal(loc=172, scale=10, size=sample_size)\n",
        "sample_mean = np.mean(sample_data)\n",
        "\n",
        "# Perform a one-sample Z-test\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # two-tailed\n",
        "\n",
        "# Display results\n",
        "print(\"Sample Data:\", np.round(sample_data, 2))\n",
        "print(f\"\\nSample Mean = {sample_mean:.2f}\")\n",
        "print(f\"Z-score = {z_score:.4f}\")\n",
        "print(f\"P-value = {p_value:.4f}\")\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Define the sample data\n",
        "sample_data = [102, 100, 98, 101, 99, 100, 97, 103, 99, 98]  # Example sample\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Step 2: Define known population parameters\n",
        "population_mean = 100\n",
        "population_std = 2  # Known standard deviation\n",
        "\n",
        "# Step 3: Calculate the Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Step 4: Calculate the two-tailed P-value\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 5: Output results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 6: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: Sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between sample and population mean.\")\n"
      ],
      "metadata": {
        "id": "fOegPuStnRDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Define sample and population parameters\n",
        "sample_data = [102, 100, 98, 101, 99, 100, 97, 103, 99, 98]\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "population_mean = 100\n",
        "population_std = 2  # Known population standard deviation\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "# Step 2: Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: Print results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n",
        "# Step 4: Visualization\n",
        "z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "# Create range for x-axis\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x, 0, 1)  # standard normal curve\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x, y, label='Standard Normal Distribution', color='blue')\n",
        "\n",
        "# Fill critical regions\n",
        "plt.fill_between(x, y, where=(x <= -z_critical), color='red', alpha=0.5, label='Rejection Region (Left)')\n",
        "plt.fill_between(x, y, where=(x >= z_critical), color='red', alpha=0.5, label='Rejection Region (Right)')\n",
        "\n",
        "# Mark observed Z-score\n",
        "plt.axvline(z_score, color='green', linestyle='--', linewidth=2, label=f'Observed Z = {z_score:.2f}')\n",
        "\n",
        "# Add annotations\n",
        "plt.title('Two-Tailed Z-Test with Rejection Regions')\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RbgqKKPEnQ_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu0=100, mu1=103, sigma=10, n=30, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II errors for hypothesis testing.\n",
        "\n",
        "    Parameters:\n",
        "        mu0 (float): Mean under null hypothesis (H0)\n",
        "        mu1 (float): Mean under alternative hypothesis (H1)\n",
        "        sigma (float): Population standard deviation\n",
        "        n (int): Sample size\n",
        "        alpha (float): Significance level\n",
        "    \"\"\"\n",
        "    # Standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Critical value (two-tailed test)\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "    x_crit_low = mu0 - z_critical * se\n",
        "    x_crit_high = mu0 + z_critical * se\n",
        "\n",
        "    # Plotting range\n",
        "    x = np.linspace(mu0 - 4*se, mu1 + 4*se, 1000)\n",
        "\n",
        "    # Distributions under H0 and H1\n",
        "    y0 = norm.pdf(x, mu0, se)\n",
        "    y1 = norm.pdf(x, mu1, se)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y0, label='H₀: μ = {}'.format(mu0), color='blue')\n",
        "    plt.plot(x, y1, label='H₁: μ = {}'.format(mu1), color='orange')\n",
        "\n",
        "    # Type I Error: Reject H₀ when it's true (Red)\n",
        "    plt.fill_between(x, y0, where=(x < x_crit_low) | (x > x_crit_high), color='red', alpha=0.3, label='Type I Error (α)')\n",
        "\n",
        "    # Type II Error: Fail to reject H₀ when H₁ is true (Purple)\n",
        "    plt.fill_between(x, y1, where=(x > x_crit_low) & (x < x_crit_high), color='purple', alpha=0.3, label='Type II Error (β)')\n",
        "\n",
        "    # Decision boundary\n",
        "    plt.axvline(x_crit_low, color='black', linestyle='--')\n",
        "    plt.axvline(x_crit_high, color='black', linestyle='--')\n",
        "\n",
        "    plt.title('Type I and Type II Errors Visualization')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Calculating beta (Type II error probability)\n",
        "    beta = norm.cdf(x_crit_high, mu1, se) - norm.cdf(x_crit_low, mu1, se)\n",
        "    power = 1 - beta\n",
        "\n",
        "    print(f\"Critical values: {x_crit_low:.2f}, {x_crit_high:.2f}\")\n",
        "    print(f\"Type I error rate (α): {alpha}\")\n",
        "    print(f\"Type II error rate (β): {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - β): {power:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "visualize_type1_type2_errors()\n"
      ],
      "metadata": {
        "id": "s5o-imINnQ8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to perform an independent T-test and interpret the results\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Step 1: Define two independent sample datasets\n",
        "group1 = [88, 92, 85, 91, 87, 90, 86]\n",
        "group2 = [84, 83, 89, 81, 85, 87, 82]\n",
        "\n",
        "# Step 2: Perform the independent t-test\n",
        "t_stat, p_value = ttest_ind(group1, group2, equal_var=True)  # assume equal variances\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"Group 1 Mean:\", np.mean(group1))\n",
        "print(\"Group 2 Mean:\", np.mean(group2))\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the two groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the two groups.\")\n"
      ],
      "metadata": {
        "id": "4JRa6D07nQ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a paired sample T-test using Python and visualize the comparison results\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Step 1: Define paired sample data (before and after treatment, for example)\n",
        "before = [88, 90, 85, 87, 86, 91, 89, 90, 88, 84]\n",
        "after =  [91, 93, 86, 89, 88, 92, 90, 91, 90, 86]\n",
        "\n",
        "# Step 2: Perform paired sample t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"Mean (Before):\", np.mean(before))\n",
        "print(\"Mean (After):\", np.mean(after))\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the paired samples.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the paired samples.\")\n",
        "\n",
        "# Step 5: Visualization - Line plot for individual changes\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Line plot\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(len(before)):\n",
        "    plt.plot(['Before', 'After'], [before[i], after[i]], marker='o', linestyle='-', color='gray')\n",
        "plt.title('Paired Sample Line Plot')\n",
        "plt.ylabel('Scores')\n",
        "plt.grid(True)\n",
        "\n",
        "# Boxplot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.boxplot([before, after], labels=['Before', 'After'])\n",
        "plt.title('Before vs After Comparison')\n",
        "plt.ylabel('Scores')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ln5KSmDSnQ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(42)\n",
        "true_mean = 100\n",
        "sample_size = 25\n",
        "population_std = 10  # Known for Z-test\n",
        "sample_data = np.random.normal(loc=102, scale=10, size=sample_size)\n",
        "\n",
        "# Sample statistics\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std = np.std(sample_data, ddof=1)  # ddof=1 for sample std dev\n",
        "\n",
        "# Step 2: Perform Z-test\n",
        "z_score = (sample_mean - true_mean) / (population_std / np.sqrt(sample_size))\n",
        "z_p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: Perform one-sample T-test\n",
        "t_score = (sample_mean - true_mean) / (sample_std / np.sqrt(sample_size))\n",
        "t_p_value = 2 * (1 - t.cdf(abs(t_score), df=sample_size - 1))\n",
        "\n",
        "# Step 4: Output comparison\n",
        "print(\"===== Sample Info =====\")\n",
        "print(f\"Sample Mean     = {sample_mean:.2f}\")\n",
        "print(f\"Sample Std Dev  = {sample_std:.2f}\")\n",
        "print(f\"Sample Size     = {sample_size}\\n\")\n",
        "\n",
        "print(\"===== Z-test Results (σ known) =====\")\n",
        "print(f\"Z-score         = {z_score:.4f}\")\n",
        "print(f\"P-value         = {z_p_value:.4f}\")\n",
        "print(\"Assumes known population std deviation.\\n\")\n",
        "\n",
        "print(\"===== T-test Results (σ unknown) =====\")\n",
        "print(f\"T-score         = {t_score:.4f}\")\n",
        "print(f\"P-value         = {t_p_value:.4f}\")\n",
        "print(\"Uses sample std deviation.\\n\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "z_result = \"Reject H0\" if z_p_value < alpha else \"Fail to reject H0\"\n",
        "t_result = \"Reject H0\" if t_p_value < alpha else \"Fail to reject H0\"\n",
        "\n",
        "print(\"===== Conclusion =====\")\n",
        "print(f\"Z-test decision: {z_result}\")\n",
        "print(f\"T-test decision: {t_result}\")\n"
      ],
      "metadata": {
        "id": "Bfgr0aAZnQx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python function to calculate the confidence interval for a sample mean and explain its significance\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): Sample data\n",
        "        confidence (float): Confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "        (mean, lower_bound, upper_bound)\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    t_crit = t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "    lower = mean - margin_of_error\n",
        "    upper = mean + margin_of_error\n",
        "\n",
        "    return mean, lower, upper\n",
        "\n",
        "# Example usage\n",
        "sample_data = [88, 92, 85, 91, 87, 90, 86, 89, 93, 88]\n",
        "mean, lower, upper = confidence_interval(sample_data)\n",
        "\n",
        "print(f\"Sample Mean: {mean:.2f}\")\n",
        "print(f\"95% Confidence Interval: ({lower:.2f}, {upper:.2f})\")\n"
      ],
      "metadata": {
        "id": "imzgIK9CnQuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "\n",
        "def calculate_margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for the sample mean at a given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or array): Sample data\n",
        "        confidence (float): Confidence level (default = 0.95)\n",
        "\n",
        "    Returns:\n",
        "        margin_of_error (float)\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    sample_std = np.std(data, ddof=1)  # sample standard deviation\n",
        "    std_error = sample_std / np.sqrt(n)  # standard error of the mean\n",
        "    t_critical = t.ppf((1 + confidence) / 2, df=n - 1)  # t-critical value\n",
        "    margin_of_error = t_critical * std_error\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "sample_data = [45, 50, 55, 52, 48, 49, 53, 51, 47, 54]\n",
        "confidence_level = 0.95\n",
        "\n",
        "moe = calculate_margin_of_error(sample_data, confidence_level)\n",
        "print(f\"Margin of Error at {int(confidence_level * 100)}% confidence: ±{moe:.2f}\")\n"
      ],
      "metadata": {
        "id": "Nb29sT5ZnQqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "\n",
        "def bayes_theorem(prior_H, likelihood_E_given_H, likelihood_E_given_not_H):\n",
        "    \"\"\"\n",
        "    Compute the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "        prior_H: Prior probability of hypothesis H\n",
        "        likelihood_E_given_H: Likelihood of evidence given H is true\n",
        "        likelihood_E_given_not_H: Likelihood of evidence given H is false\n",
        "\n",
        "    Returns:\n",
        "        posterior_H: Updated probability of H given E\n",
        "    \"\"\"\n",
        "    prior_not_H = 1 - prior_H\n",
        "\n",
        "    # Total probability of evidence\n",
        "    marginal_E = (likelihood_E_given_H * prior_H) + (likelihood_E_given_not_H * prior_not_H)\n",
        "\n",
        "    # Bayes' theorem\n",
        "    posterior_H = (likelihood_E_given_H * prior_H) / marginal_E\n",
        "\n",
        "    return posterior_H\n",
        "\n",
        "# Example scenario:\n",
        "# A medical test for a disease is 99% accurate (true positive rate),\n",
        "# but the disease prevalence in the population is only 1%.\n",
        "\n",
        "prior = 0.01                        # P(Disease)\n",
        "likelihood = 0.99                  # P(Positive Test | Disease)\n",
        "false_positive = 0.05              # P(Positive Test | No Disease)\n",
        "\n",
        "posterior = bayes_theorem(prior, likelihood, false_positive)\n",
        "\n",
        "print(f\"Probability of having the disease given a positive test result: {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "gxRs1cw7nQlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a Chi-square test for independence between two categorical variables in Python\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Step 1: Create a contingency table\n",
        "# Example: Relationship between Gender and Preference\n",
        "#          Preference\n",
        "# Gender     A   B\n",
        "#   M       20  30\n",
        "#   F       25  25\n",
        "\n",
        "data = [[20, 30],\n",
        "        [25, 25]]\n",
        "labels = ['Male', 'Female']\n",
        "columns = ['Pref A', 'Pref B']\n",
        "\n",
        "# Convert to DataFrame (optional for clarity)\n",
        "table = pd.DataFrame(data, index=labels, columns=columns)\n",
        "print(\"Contingency Table:\")\n",
        "print(table)\n",
        "\n",
        "# Step 2: Perform the Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"\\nChi-square Test Results:\")\n",
        "print(f\"Chi2 Statistic = {chi2:.4f}\")\n",
        "print(f\"Degrees of Freedom = {dof}\")\n",
        "print(f\"P-value = {p:.4f}\")\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(pd.DataFrame(expected, index=labels, columns=columns))\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"\\nConclusion: Reject the null hypothesis — the variables are dependent (associated).\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Fail to reject the null hypothesis — the variables are independent.\")\n"
      ],
      "metadata": {
        "id": "ETrwhCo6nQfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define observed data (contingency table)\n",
        "# Example: Product preference by gender\n",
        "observed = np.array([\n",
        "    [20, 30],  # Male\n",
        "    [25, 25]   # Female\n",
        "])\n",
        "\n",
        "row_labels = ['Male', 'Female']\n",
        "col_labels = ['Preference A', 'Preference B']\n",
        "\n",
        "# Step 2: Convert to DataFrame for clarity\n",
        "observed_df = pd.DataFrame(observed, index=row_labels, columns=col_labels)\n",
        "\n",
        "# Step 3: Calculate row totals, column totals, and grand total\n",
        "row_totals = observed.sum(axis=1).reshape(-1, 1)\n",
        "col_totals = observed.sum(axis=0).reshape(1, -1)\n",
        "grand_total = observed.sum()\n",
        "\n",
        "# Step 4: Calculate expected frequencies\n",
        "expected = (row_totals @ col_totals) / grand_total\n",
        "\n",
        "# Step 5: Display results\n",
        "expected_df = pd.DataFrame(expected, index=row_labels, columns=col_labels)\n",
        "\n",
        "print(\"Observed Frequencies:\\n\", observed_df)\n",
        "print(\"\\nExpected Frequencies:\\n\", expected_df.round(2))\n",
        "\n"
      ],
      "metadata": {
        "id": "oaDCqMv-pCns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Step 1: Define observed and expected frequencies\n",
        "# Example: Rolling a die 60 times — does it appear fair?\n",
        "observed = np.array([8, 9, 10, 11, 12, 10])  # observed counts for sides 1 to 6\n",
        "expected = np.array([10, 10, 10, 10, 10, 10])  # expected if die is fair\n",
        "\n",
        "# Step 2: Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"Observed Frequencies:\", observed)\n",
        "print(\"Expected Frequencies:\", expected)\n",
        "print(f\"\\nChi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nConclusion: Reject the null hypothesis — observed data does NOT fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Fail to reject the null hypothesis — observed data fits the expected distribution.\")\n"
      ],
      "metadata": {
        "id": "_D-4vjnWpCkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement an F-test using Python to compare the variances of two random samples\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "def f_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a two-tailed F-test to compare variances of two samples.\n",
        "\n",
        "    Parameters:\n",
        "        sample1, sample2: Input arrays of sample data\n",
        "        alpha: Significance level (default = 0.05)\n",
        "\n",
        "    Returns:\n",
        "        f_statistic, p_value, conclusion\n",
        "    \"\"\"\n",
        "    # Sample variances\n",
        "    var1 = np.var(sample1, ddof=1)\n",
        "    var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "    # Degrees of freedom\n",
        "    df1 = len(sample1) - 1\n",
        "    df2 = len(sample2) - 1\n",
        "\n",
        "    # Ensure the larger variance is numerator (F ≥ 1)\n",
        "    if var1 > var2:\n",
        "        f_stat = var1 / var2\n",
        "        dfn, dfd = df1, df2\n",
        "    else:\n",
        "        f_stat = var2 / var1\n",
        "        dfn, dfd = df2, df1\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * min(f.cdf(f_stat, dfn, dfd), 1 - f.cdf(f_stat, dfn, dfd))\n",
        "\n",
        "    # Conclusion\n",
        "    conclusion = \"Reject null hypothesis: variances are significantly different.\" \\\n",
        "        if p_value < alpha else \"Fail to reject null hypothesis: no significant difference in variances.\"\n",
        "\n",
        "    return f_stat, p_value, conclusion\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(50, 10, 30)  # mean=50, std=10\n",
        "sample2 = np.random.normal(50, 15, 30)  # mean=50, std=15\n",
        "\n",
        "f_statistic, p_val, decision = f_test(sample1, sample2)\n",
        "\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "print(f\"Conclusion: {decision}\")\n"
      ],
      "metadata": {
        "id": "1DvWMwPBpCdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Step 1: Set parameters\n",
        "df = 5  # degrees of freedom\n",
        "x = np.linspace(0, 30, 500)\n",
        "pdf_values = chi2.pdf(x, df)\n",
        "\n",
        "# Step 2: Plot the Chi-square distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, pdf_values, label=f'Chi-square (df={df})', color='blue')\n",
        "plt.fill_between(x, pdf_values, alpha=0.2)\n",
        "plt.title(f'Chi-square Distribution with {df} Degrees of Freedom')\n",
        "plt.xlabel('Chi-square Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Av8Fo_q6pCgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Define sample data for 3 groups\n",
        "group1 = [88, 92, 85, 91, 87]\n",
        "group2 = [78, 74, 80, 76, 79]\n",
        "group3 = [94, 96, 92, 95, 97]\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"Means:\")\n",
        "print(f\"Group 1 Mean: {np.mean(group1):.2f}\")\n",
        "print(f\"Group 2 Mean: {np.mean(group2):.2f}\")\n",
        "print(f\"Group 3 Mean: {np.mean(group3):.2f}\\n\")\n",
        "\n",
        "print(\"ANOVA Test Result:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nConclusion: Reject the null hypothesis — at least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Fail to reject the null hypothesis — no significant difference in group means.\")\n"
      ],
      "metadata": {
        "id": "xqKw7GtjpCZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Define sample data for 3 groups\n",
        "group_A = [88, 92, 85, 91, 87]\n",
        "group_B = [78, 74, 80, 76, 79]\n",
        "group_C = [94, 96, 92, 95, 97]\n",
        "\n",
        "groups = [group_A, group_B, group_C]\n",
        "labels = ['Group A', 'Group B', 'Group C']\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group_A, group_B, group_C)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"Group Means:\")\n",
        "for label, group in zip(labels, groups):\n",
        "    print(f\"{label}: {np.mean(group):.2f}\")\n",
        "\n",
        "print(\"\\nANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nConclusion: Reject H₀ — At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Fail to reject H₀ — No significant difference in group means.\")\n",
        "\n",
        "# Step 4: Visualization - Boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(groups, labels=labels)\n",
        "plt.title('Group Comparison Using One-Way ANOVA')\n",
        "plt.ylabel('Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YhYqYStvpCWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import shapiro, levene\n",
        "import pandas as pd\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    \"\"\"\n",
        "    Checks ANOVA assumptions: normality and equal variance.\n",
        "\n",
        "    Parameters:\n",
        "        groups: Variable number of group arrays (lists or numpy arrays)\n",
        "\n",
        "    Prints:\n",
        "        Shapiro-Wilk test results for normality\n",
        "        Levene's test result for equal variances\n",
        "    \"\"\"\n",
        "    print(\"=== Checking Normality (Shapiro-Wilk Test) ===\")\n",
        "    for i, group in enumerate(groups, 1):\n",
        "        stat, p = shapiro(group)\n",
        "        print(f\"Group {i}: W={stat:.4f}, p={p:.4f} -> {'Normal' if p > 0.05 else 'Not Normal'}\")\n",
        "\n",
        "    print(\"\\n=== Checking Equal Variance (Levene's Test) ===\")\n",
        "    levene_stat, levene_p = levene(*groups)\n",
        "    print(f\"Levene’s Test: Stat={levene_stat:.4f}, p={levene_p:.4f} -> {'Equal variances' if levene_p > 0.05 else 'Unequal variances'}\")\n"
      ],
      "metadata": {
        "id": "8mkkre_2pCTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Step 1: Simulate data for two factors (e.g., Drug and Gender)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Factors\n",
        "gender = ['Male', 'Female']\n",
        "drug = ['A', 'B']\n",
        "\n",
        "# Create a DataFrame\n",
        "data = []\n",
        "for g in gender:\n",
        "    for d in drug:\n",
        "        for _ in range(10):  # 10 observations per group\n",
        "            effect = 5 if g == 'Female' else 0\n",
        "            treatment = 3 if d == 'B' else 0\n",
        "            interaction = 2 if (g == 'Female' and d == 'B') else 0\n",
        "            score = 50 + effect + treatment + interaction + np.random.normal(0, 2)\n",
        "            data.append([g, d, score])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Gender', 'Drug', 'Score'])\n",
        "\n",
        "# Step 2: Perform two-way ANOVA\n",
        "model = ols('Score ~ C(Gender) + C(Drug) + C(Gender):C(Drug)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"=== Two-Way ANOVA Results ===\")\n",
        "print(anova_table)\n",
        "\n",
        "# Step 3: Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Drug', y='Score', hue='Gender', data=df)\n",
        "plt.title('Two-Way ANOVA: Drug and Gender Interaction')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zS7Ax7E7pCPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Step 1: Define degrees of freedom for numerator and denominator\n",
        "dfn = 5   # Degrees of freedom for the numerator\n",
        "dfd = 20  # Degrees of freedom for the denominator\n",
        "\n",
        "# Step 2: Generate F-distribution values\n",
        "x = np.linspace(0, 5, 500)\n",
        "pdf = f.pdf(x, dfn, dfd)\n",
        "\n",
        "# Step 3: Plot the F-distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, pdf, 'b-', label=f'F-distribution (dfn={dfn}, dfd={dfd})')\n",
        "plt.fill_between(x, pdf, color='skyblue', alpha=0.4)\n",
        "plt.title('F-Distribution')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "\n",
        "# Step 4: Add critical region for alpha = 0.05\n",
        "alpha = 0.05\n",
        "f_critical = f.ppf(1 - alpha, dfn, dfd)\n",
        "plt.axvline(f_critical, color='red', linestyle='--', label=f'Critical F-value (α={alpha}) ≈ {f_critical:.2f}')\n",
        "plt.fill_between(x[x > f_critical], pdf[x > f_critical], color='red', alpha=0.3)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sQBR3LIIpCLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import f_oneway\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create sample data for three groups\n",
        "group1 = [88, 92, 85, 91, 87]\n",
        "group2 = [78, 74, 80, 76, 79]\n",
        "group3 = [94, 96, 92, 95, 97]\n",
        "\n",
        "# Combine data into a DataFrame for visualization\n",
        "data = {\n",
        "    'Score': group1 + group2 + group3,\n",
        "    'Group': ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"=== One-Way ANOVA Test ===\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Conclusion: Reject H₀ — At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference in group means.\")\n",
        "\n",
        "# Step 4: Visualize with boxplots\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Group', y='Score', data=df, palette=\"Set2\")\n",
        "plt.title('Group Comparison using One-Way ANOVA')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2CWOaO5ZqNLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Simulate random data from normal distributions\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=50, scale=5, size=100)  # Mean=50, SD=5\n",
        "sample2 = np.random.normal(loc=52, scale=5, size=100)  # Mean=52, SD=5\n",
        "\n",
        "# Step 2: Perform independent t-test\n",
        "t_stat, p_value = ttest_ind(sample1, sample2)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"=== Independent Two-Sample T-Test ===\")\n",
        "print(f\"Sample 1 Mean: {np.mean(sample1):.2f}\")\n",
        "print(f\"Sample 2 Mean: {np.mean(sample2):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject H₀ — Means are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference in means.\")\n",
        "\n",
        "# Step 4: Visualize distributions\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(sample1, kde=True, label='Sample 1 (Mean=50)', color='blue', stat=\"density\", bins=20)\n",
        "sns.histplot(sample2, kde=True, label='Sample 2 (Mean=52)', color='orange', stat=\"density\", bins=20)\n",
        "plt.axvline(np.mean(sample1), color='blue', linestyle='--')\n",
        "plt.axvline(np.mean(sample2), color='orange', linestyle='--')\n",
        "plt.title('Comparison of Two Normal Distributions')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "itk-z2ARqNH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Step 1: Sample data and parameters\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=100, scale=10, size=30)  # Population std=10\n",
        "\n",
        "# Hypothesized population variance\n",
        "sigma0_squared = 100  # i.e., std = 10\n",
        "\n",
        "# Step 2: Calculate sample variance\n",
        "n = len(sample)\n",
        "sample_var = np.var(sample, ddof=1)\n",
        "\n",
        "# Step 3: Compute Chi-square statistic\n",
        "chi2_stat = (n - 1) * sample_var / sigma0_squared\n",
        "\n",
        "# Step 4: Compute critical values for two-tailed test\n",
        "alpha = 0.05\n",
        "chi2_lower = chi2.ppf(alpha / 2, df=n - 1)\n",
        "chi2_upper = chi2.ppf(1 - alpha / 2, df=n - 1)\n",
        "\n",
        "# Step 5: Output results\n",
        "print(\"=== Chi-square Test for Population Variance ===\")\n",
        "print(f\"Sample Variance: {sample_var:.4f}\")\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: {n - 1}\")\n",
        "print(f\"Critical Values: Lower={chi2_lower:.4f}, Upper={chi2_upper:.4f}\")\n",
        "\n",
        "# Step 6: Interpret the result\n",
        "if chi2_stat < chi2_lower or chi2_stat > chi2_upper:\n",
        "    print(\"Conclusion: Reject H₀ — Variance is significantly different from hypothesized.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference in variance.\")\n"
      ],
      "metadata": {
        "id": "7Zu9Y5D-qNEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Python script to perform a Z-test for comparing proportions between two datasets or groups\n",
        "\n",
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Step 1: Define successes and observations for two groups\n",
        "# Example: Group A: 40 successes out of 100\n",
        "#          Group B: 55 successes out of 120\n",
        "\n",
        "successes = np.array([40, 55])\n",
        "n_obs = np.array([100, 120])\n",
        "\n",
        "# Step 2: Perform the Z-test\n",
        "z_stat, p_value = proportions_ztest(count=successes, nobs=n_obs)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(\"=== Z-Test for Two Proportions ===\")\n",
        "print(f\"Group A: {successes[0]}/{n_obs[0]} = {successes[0]/n_obs[0]:.3f}\")\n",
        "print(f\"Group B: {successes[1]}/{n_obs[1]} = {successes[1]/n_obs[1]:.3f}\")\n",
        "print(f\"\\nZ-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject H₀ — The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference in proportions.\")\n"
      ],
      "metadata": {
        "id": "CgmamWMTqbwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Step 1: Generate two random samples\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # std=10\n",
        "sample2 = np.random.normal(loc=50, scale=15, size=30)  # std=15\n",
        "\n",
        "# Step 2: Calculate sample variances\n",
        "var1 = np.var(sample1, ddof=1)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Ensure F >= 1 by setting larger variance in numerator\n",
        "if var1 > var2:\n",
        "    f_stat = var1 / var2\n",
        "    dfn, dfd = len(sample1) - 1, len(sample2) - 1\n",
        "else:\n",
        "    f_stat = var2 / var1\n",
        "    dfn, dfd = len(sample2) - 1, len(sample1) - 1\n",
        "\n",
        "# Step 3: Set significance level and compute critical values\n",
        "alpha = 0.05\n",
        "f_critical_low = f.ppf(alpha / 2, dfn, dfd)\n",
        "f_critical_high = f.ppf(1 - alpha / 2, dfn, dfd)\n",
        "\n",
        "# Step 4: Output test result\n",
        "print(\"=== F-Test for Equality of Variances ===\")\n",
        "print(f\"Sample 1 Variance: {var1:.4f}\")\n",
        "print(f\"Sample 2 Variance: {var2:.4f}\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: df1={dfn}, df2={dfd}\")\n",
        "print(f\"Critical Values: Lower={f_critical_low:.4f}, Upper={f_critical_high:.4f}\")\n",
        "\n",
        "if f_stat < f_critical_low or f_stat > f_critical_high:\n",
        "    print(\"Conclusion: Reject H₀ — The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference in variances.\")\n",
        "\n",
        "# Step 5: Visualization of F-distribution\n",
        "x = np.linspace(0.1, 5, 500)\n",
        "y = f.pdf(x, dfn, dfd)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-', label=f'F-distribution (df1={dfn}, df2={dfd})')\n",
        "plt.fill_between(x, y, where=(x < f_critical_low) | (x > f_critical_high), color='red', alpha=0.3, label='Rejection region')\n",
        "plt.axvline(f_stat, color='green', linestyle='--', label=f'F-statistic = {f_stat:.2f}')\n",
        "plt.title(\"F-Test for Comparing Two Variances\")\n",
        "plt.xlabel(\"F-value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "91H321-3qbtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a Chi-square test for goodness of fit with simulated data and analyze the results\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate observed data\n",
        "# Example: 6 categories (like dice faces), not equally likely\n",
        "np.random.seed(42)\n",
        "observed = np.random.multinomial(120, [0.15, 0.20, 0.20, 0.10, 0.15, 0.20])\n",
        "\n",
        "# Step 2: Define expected frequencies (uniform or custom)\n",
        "# Let's test if it's uniformly distributed\n",
        "expected = np.full_like(observed, fill_value=np.sum(observed) / len(observed))\n",
        "\n",
        "# Step 3: Perform the Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Output the results\n",
        "print(\"=== Chi-square Goodness-of-Fit Test ===\")\n",
        "print(f\"Observed: {observed}\")\n",
        "print(f\"Expected: {expected}\")\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject H₀ — The observed distribution significantly differs from expected.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject H₀ — No significant difference from the expected distribution.\")\n",
        "\n",
        "# Step 5: Visualize the observed vs. expected frequencies\n",
        "categories = [f'Cat {i+1}' for i in range(len(observed))]\n",
        "x = np.arange(len(categories))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(x - 0.2, observed, width=0.4, label='Observed', color='skyblue')\n",
        "plt.bar(x + 0.2, expected, width=0.4, label='Expected', color='orange')\n",
        "plt.xticks(x, categories)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Chi-square Goodness-of-Fit: Observed vs Expected\")\n",
        "plt.legend()\n",
        "plt.grid(True, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gdo37aYKqniH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}